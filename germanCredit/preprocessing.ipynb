{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6eabb54-df64-4136-8fb4-73340578c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Using cached ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from ucimlrepo) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/conda/lib/python3.12/site-packages (from ucimlrepo) (2025.8.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
      "Using cached ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7863782-7ab2-43e8-973a-af0dcfd609c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {1: 0, 2: 1}\n",
      "Categorical columns: ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
      "Numeric columns: ['Attribute2', 'Attribute5', 'Attribute8', 'Attribute11', 'Attribute13', 'Attribute16', 'Attribute18']\n",
      "[Split 1] seed=42 saved:\n",
      "  data/germancredit_split1_train.csv  -> (800, 64)\n",
      "  data/germancredit_split1_test.csv   -> (200, 64)\n",
      "[Split 2] seed=202 saved:\n",
      "  data/germancredit_split2_train.csv  -> (800, 64)\n",
      "  data/germancredit_split2_test.csv   -> (200, 64)\n",
      "[Split 3] seed=777 saved:\n",
      "  data/germancredit_split3_train.csv  -> (800, 64)\n",
      "  data/germancredit_split3_test.csv   -> (200, 64)\n",
      "[Split 4] seed=1234 saved:\n",
      "  data/germancredit_split4_train.csv  -> (800, 64)\n",
      "  data/germancredit_split4_test.csv   -> (200, 64)\n",
      "[Split 5] seed=9001 saved:\n",
      "  data/germancredit_split5_train.csv  -> (800, 64)\n",
      "  data/germancredit_split5_test.csv   -> (200, 64)\n",
      "\n",
      "Done. Created 5 train/test splits in 'data/' with model features + target + (gender, age).\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# importing libraries\n",
    "# -------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import inspect\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# -------------------------------\n",
    "# fetching the dataset\n",
    "# -------------------------------\n",
    "statlog_german_credit_data = fetch_ucirepo(id=144)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = statlog_german_credit_data.data.features.copy()\n",
    "y = statlog_german_credit_data.data.targets\n",
    "\n",
    "# If y is a DataFrame, squeeze to Series\n",
    "if isinstance(y, pd.DataFrame):\n",
    "    y = y.iloc[:, 0]\n",
    "\n",
    "# -------------------------------\n",
    "# derive sensitive attributes\n",
    "# -------------------------------\n",
    "# UCI Attribute 9: Personal status and sex\n",
    "gender_map = {\"A91\": \"male\", \"A92\": \"female\", \"A93\": \"male\", \"A94\": \"male\", \"A95\": \"female\"}\n",
    "if \"Attribute9\" not in X.columns:\n",
    "    raise KeyError(\"Expected 'Attribute9' for gender derivation.\")\n",
    "X[\"gender\"] = X[\"Attribute9\"].map(gender_map)\n",
    "\n",
    "# Age is Attribute13 in this schema\n",
    "if \"Attribute13\" not in X.columns:\n",
    "    raise KeyError(\"Expected 'Attribute13' for age.\")\n",
    "X[\"age\"] = pd.to_numeric(X[\"Attribute13\"], errors=\"coerce\")\n",
    "\n",
    "# -------------------------------\n",
    "# encode target to 0/1 (e.g., bad/good)\n",
    "# -------------------------------\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(np.asarray(y))\n",
    "print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# -------------------------------\n",
    "# build model feature frame (exclude sensitive columns from preprocessing)\n",
    "# -------------------------------\n",
    "sensitive_cols = [\"gender\", \"age\"]  # race removed\n",
    "feature_X = X.drop(columns=sensitive_cols, errors=\"ignore\")\n",
    "\n",
    "# column types on model features\n",
    "cat_cols = feature_X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "num_cols = feature_X.select_dtypes(exclude=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "\n",
    "# -------------------------------\n",
    "# pipelines\n",
    "# -------------------------------\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Robust to sklearn version differences: sparse vs sparse_output\n",
    "ohe_params = {}\n",
    "if \"sparse_output\" in inspect.signature(OneHotEncoder).parameters:\n",
    "    ohe_params[\"sparse_output\"] = False  # sklearn >= 1.2\n",
    "else:\n",
    "    ohe_params[\"sparse\"] = False         # sklearn < 1.2\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", **ohe_params))\n",
    "])\n",
    "\n",
    "def make_preprocessor():\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipe, num_cols),\n",
    "            (\"cat\", categorical_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "# -------------------------------\n",
    "# split test and training data first before preprocessing\n",
    "# -------------------------------\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "seeds = [42, 202, 777, 1234, 9001]\n",
    "\n",
    "for i, seed in enumerate(seeds, start=1):\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "        feature_X, y_encoded, test_size=0.20, random_state=seed, stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    # keep sensitive columns aligned (raw, unencoded)\n",
    "    sens_train = X.loc[X_train_raw.index, sensitive_cols].copy()\n",
    "    sens_test  = X.loc[X_test_raw.index, sensitive_cols].copy()\n",
    "\n",
    "    preprocessor = make_preprocessor()\n",
    "\n",
    "    # fit on training only\n",
    "    X_train_processed = preprocessor.fit_transform(X_train_raw)\n",
    "    X_test_processed  = preprocessor.transform(X_test_raw)\n",
    "\n",
    "    # robust feature names\n",
    "    try:\n",
    "        processed_feature_names = preprocessor.get_feature_names_out()\n",
    "    except AttributeError:\n",
    "        ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        try:\n",
    "            ohe_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "        except AttributeError:\n",
    "            ohe_feature_names = ohe.get_feature_names(cat_cols)\n",
    "        processed_feature_names = np.array(list(num_cols) + list(ohe_feature_names))\n",
    "\n",
    "    # build DataFrames\n",
    "    df_train = pd.DataFrame(X_train_processed, columns=processed_feature_names, index=X_train_raw.index)\n",
    "    df_test  = pd.DataFrame(X_test_processed,  columns=processed_feature_names, index=X_test_raw.index)\n",
    "\n",
    "    # add target\n",
    "    df_train[\"target\"] = y_train\n",
    "    df_test[\"target\"] = y_test\n",
    "\n",
    "    # append sensitive columns (for fairness eval later)\n",
    "    for col in sensitive_cols:\n",
    "        df_train[col] = sens_train[col].values\n",
    "        df_test[col]  = sens_test[col].values\n",
    "\n",
    "    # save\n",
    "    train_path = f\"data/germancredit_split{i}_train.csv\"\n",
    "    test_path  = f\"data/germancredit_split{i}_test.csv\"\n",
    "    df_train.to_csv(train_path, index=False)\n",
    "    df_test.to_csv(test_path, index=False)\n",
    "\n",
    "    print(f\"[Split {i}] seed={seed} saved:\")\n",
    "    print(f\"  {train_path}  -> {df_train.shape}\")\n",
    "    print(f\"  {test_path}   -> {df_test.shape}\")\n",
    "\n",
    "print(\"\\nDone. Created 5 train/test splits in 'data/' with model features + target + (gender, age).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c471dd4-e004-4510-8988-1ec0f05e33da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
