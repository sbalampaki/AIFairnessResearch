{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd020f9-7dad-4331-ab83-11156959c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target encoded to 0/1 (1 = readmitted within 30 days).\n",
      "Age diagnostics:\n",
      "  dtype: object\n",
      "  NaN rate: 0.0\n",
      "  head values: [\"'30 years or younger'\", \"'30 years or younger'\", \"'30 years or younger'\", \"'30-60 years'\", \"'30-60 years'\"]\n",
      "Sanity check value counts (after fix):\n",
      "medicare:\n",
      " medicare\n",
      "False    69327\n",
      "True     32439\n",
      "Name: count, dtype: int64\n",
      "medicaid:\n",
      " medicaid\n",
      "False    98234\n",
      "True      3532\n",
      "Name: count, dtype: int64\n",
      "Categorical columns (15): ['race', 'gender', 'discharge_disposition_id', 'admission_source_id', 'medical_specialty', 'primary_diagnosis', 'max_glu_serum', 'A1Cresult', 'insulin', 'change', 'diabetesMed', 'had_emergency', 'had_inpatient_days', 'had_outpatient_days', 'readmitted']\n",
      "Numeric columns (6): ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_diagnoses', 'readmit_binary']\n",
      "[Split 1] seed=42 saved:\n",
      "  data/diab_hosp_split1_train.csv -> (81412, 60)\n",
      "  data/diab_hosp_split1_test.csv  -> (20354, 60)\n",
      "[Split 2] seed=202 saved:\n",
      "  data/diab_hosp_split2_train.csv -> (81412, 60)\n",
      "  data/diab_hosp_split2_test.csv  -> (20354, 60)\n",
      "[Split 3] seed=777 saved:\n",
      "  data/diab_hosp_split3_train.csv -> (81412, 60)\n",
      "  data/diab_hosp_split3_test.csv  -> (20354, 60)\n",
      "[Split 4] seed=1234 saved:\n",
      "  data/diab_hosp_split4_train.csv -> (81412, 60)\n",
      "  data/diab_hosp_split4_test.csv  -> (20354, 60)\n",
      "[Split 5] seed=9001 saved:\n",
      "  data/diab_hosp_split5_train.csv -> (81412, 60)\n",
      "  data/diab_hosp_split5_test.csv  -> (20354, 60)\n",
      "\n",
      "Done. True/False values for medicare/medicaid are preserved; 5 splits saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import inspect\n",
    "\n",
    "from fairlearn.datasets import fetch_diabetes_hospital\n",
    "\n",
    "# =========================\n",
    "# 1) Load dataset\n",
    "# =========================\n",
    "bundle = fetch_diabetes_hospital()\n",
    "\n",
    "X_raw = bundle.data\n",
    "X = X_raw.copy() if isinstance(X_raw, pd.DataFrame) else pd.DataFrame(X_raw, columns=getattr(bundle, \"feature_names\", None))\n",
    "\n",
    "y_raw = bundle.target\n",
    "y = y_raw.copy() if isinstance(y_raw, pd.Series) else pd.Series(y_raw)\n",
    "\n",
    "# =========================\n",
    "# 2) Encode binary target\n",
    "# =========================\n",
    "def _clean_lab(v):\n",
    "    if pd.isna(v):\n",
    "        return np.nan\n",
    "    s = str(v).strip().lower().replace(\".\", \"\")\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "y_clean = y.apply(_clean_lab)\n",
    "positive_aliases = {\"<30\", \"yes\", \"y\", \"1\", \"true\", \"readmitted\", \"readmit30\", \"pos\", \"positive\"}\n",
    "negative_aliases = {\">30\", \"no\", \"n\", \"0\", \"false\", \"notreadmitted\", \"neg\", \"negative\"}\n",
    "\n",
    "if set(y_clean.dropna().unique()) <= {\"0\", \"1\"}:\n",
    "    y_encoded = y_clean.astype(int).values\n",
    "elif set(y_clean.dropna().unique()).issubset(positive_aliases | negative_aliases):\n",
    "    y_encoded = y_clean.apply(lambda s: 1 if s in positive_aliases else 0).astype(int).values\n",
    "else:\n",
    "    y_encoded = y_clean.apply(lambda s: 1 if s in positive_aliases else 0).astype(int).values\n",
    "\n",
    "print(\"Target encoded to 0/1 (1 = readmitted within 30 days).\")\n",
    "\n",
    "# =========================\n",
    "# 3) FAIRNESS COLUMNS (FIXED)\n",
    "#    Use existing medicare/medicaid if present; only derive if missing\n",
    "# =========================\n",
    "def _find_col(df, candidates):\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c in cols_lower:\n",
    "            return cols_lower[c]\n",
    "    return None\n",
    "\n",
    "def _coerce_bool(series):\n",
    "    \"\"\"Coerce a column to boolean without flipping existing True/False.\"\"\"\n",
    "    if pd.api.types.is_bool_dtype(series):\n",
    "        return series.astype(bool)\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        # treat nonzero as True\n",
    "        return series.astype(bool)\n",
    "    # string-like\n",
    "    s = series.astype(str).str.strip().str.lower()\n",
    "    true_set  = {\"true\", \"t\", \"1\", \"yes\", \"y\"}\n",
    "    false_set = {\"false\", \"f\", \"0\", \"no\", \"n\"}\n",
    "    mapped = s.map(lambda v: True if v in true_set else (False if v in false_set else np.nan))\n",
    "    # keep NaN if ambiguous (don’t silently flip)\n",
    "    return mapped.astype(\"boolean\").astype(object).where(~mapped.isna(), np.nan)\n",
    "\n",
    "# --- medicare ---\n",
    "medicare_col = _find_col(X, [\"medicare\"])\n",
    "if medicare_col is not None:\n",
    "    medicare = _coerce_bool(X[medicare_col])\n",
    "else:\n",
    "    # derive from payer/insurance ONLY IF column missing\n",
    "    payer_col = _find_col(X, [\n",
    "        \"payer\", \"payer_code\", \"insurance\", \"primary_payer\", \"payer_type\",\n",
    "        \"payor\", \"payor_type\", \"payment_typology\", \"payertype\", \"coverage\", \"insurance_type\"\n",
    "    ])\n",
    "    if payer_col is not None:\n",
    "        payer = X[payer_col].astype(str).str.strip().str.lower()\n",
    "        medicare = payer.str.contains(\"medicare\", na=False)\n",
    "    else:\n",
    "        raise ValueError(\"Could not find 'medicare' column or a payer/insurance column to derive it from.\")\n",
    "\n",
    "# --- medicaid ---\n",
    "medicaid_col = _find_col(X, [\"medicaid\"])\n",
    "if medicaid_col is not None:\n",
    "    medicaid = _coerce_bool(X[medicaid_col])\n",
    "else:\n",
    "    if 'payer' in locals() or (payer_col := _find_col(X, [\n",
    "        \"payer\", \"payer_code\", \"insurance\", \"primary_payer\", \"payer_type\",\n",
    "        \"payor\", \"payor_type\", \"payment_typology\", \"payertype\", \"coverage\", \"insurance_type\"\n",
    "    ])) is not None:\n",
    "        payer = X[payer_col].astype(str).str.strip().str.lower() if 'payer' not in locals() else payer\n",
    "        medicaid = payer.str.contains(\"medicaid\", na=False)\n",
    "    else:\n",
    "        raise ValueError(\"Could not find 'medicaid' column or a payer/insurance column to derive it from.\")\n",
    "\n",
    "# --- age ---\n",
    "# --- AGE (robust & prefers bundle.sensitive_features) ---\n",
    "def _find_col(df, candidates):\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c in cols_lower:\n",
    "            return cols_lower[c]\n",
    "    return None\n",
    "\n",
    "def _parse_age_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Parse numeric age from strings like '[60-70)', '60-70', '70+', '45'.\n",
    "    Returns numeric where parsed; otherwise NaN.\"\"\"\n",
    "    import re\n",
    "    s_str = s.astype(str).str.strip()\n",
    "\n",
    "    range_pat = re.compile(r\"^\\[?\\s*(\\d+)\\s*[-–]\\s*(\\d+)\\s*\\)?$\")   # [60-70) or 60-70\n",
    "    plus_pat  = re.compile(r\"^\\[?\\s*(\\d+)\\s*\\+\\)?$\")                # 70+ or [70+)\n",
    "    num_pat   = re.compile(r\"^\\d+$\")                                # 45\n",
    "\n",
    "    def _to_num(x):\n",
    "        if pd.isna(x) or x == \"\" or x.lower() in {\"nan\", \"none\"}:\n",
    "            return np.nan\n",
    "        m = range_pat.match(x)\n",
    "        if m:\n",
    "            a, b = int(m.group(1)), int(m.group(2))\n",
    "            return (a + b) / 2.0\n",
    "        m = plus_pat.match(x)\n",
    "        if m:\n",
    "            a = int(m.group(1))\n",
    "            # choose a lower-bound or midpoint heuristic; lower-bound is safer\n",
    "            return float(a)\n",
    "        m = num_pat.match(x)\n",
    "        if m:\n",
    "            return float(m.group(0))\n",
    "        return np.nan\n",
    "\n",
    "    return s_str.map(_to_num)\n",
    "\n",
    "# 1) Try bundle.sensitive_features first\n",
    "age_series = None\n",
    "sf = getattr(bundle, \"sensitive_features\", None)\n",
    "if sf is not None:\n",
    "    if isinstance(sf, pd.Series):\n",
    "        if (sf.name or \"\").lower() in {\"age\", \"age_years\", \"patient_age\"}:\n",
    "            age_series = sf.copy()\n",
    "    elif isinstance(sf, pd.DataFrame):\n",
    "        age_sf_col = _find_col(sf, [\"age\", \"age_years\", \"patient_age\"])\n",
    "        if age_sf_col is not None:\n",
    "            age_series = sf[age_sf_col].copy()\n",
    "\n",
    "# 2) Fall back to X if not found\n",
    "if age_series is None:\n",
    "    age_col = _find_col(X, [\"age\", \"age_years\", \"patient_age\"])\n",
    "    if age_col is None:\n",
    "        raise ValueError(\"Could not find an age column in bundle.sensitive_features or X.\")\n",
    "    age_series = X[age_col].copy()\n",
    "\n",
    "# 3) Make age numeric when possible; otherwise keep original for grouping\n",
    "if pd.api.types.is_numeric_dtype(age_series):\n",
    "    age_numeric = pd.to_numeric(age_series, errors=\"coerce\")\n",
    "else:\n",
    "    parsed = _parse_age_series(age_series)\n",
    "    if parsed.notna().mean() >= 0.8:\n",
    "        age_numeric = parsed\n",
    "    else:\n",
    "        # keep original strings if we can't confidently parse\n",
    "        age_numeric = age_series.astype(str).str.strip()\n",
    "X[\"age\"] = age_numeric\n",
    "\n",
    "# DIAGNOSTICS (you can keep these prints)\n",
    "print(\"Age diagnostics:\")\n",
    "print(\"  dtype:\", X[\"age\"].dtype)\n",
    "print(\"  NaN rate:\", float(pd.isna(X[\"age\"]).mean()))\n",
    "print(\"  head values:\", X[\"age\"].head().tolist())\n",
    "\n",
    "X[\"medicare\"] = medicare.astype(bool)\n",
    "X[\"medicaid\"] = medicaid.astype(bool)\n",
    "\n",
    "\n",
    "# checking if it has both true and false values\n",
    "print(\"Sanity check value counts (after fix):\")\n",
    "print(\"medicare:\\n\", pd.Series(X[\"medicare\"]).value_counts(dropna=False))\n",
    "print(\"medicaid:\\n\", pd.Series(X[\"medicaid\"]).value_counts(dropna=False))\n",
    "\n",
    "# =========================\n",
    "# 4) Exclude sensitive cols from model features\n",
    "# =========================\n",
    "sensitive_cols = [\"medicare\", \"medicaid\", \"age\"]\n",
    "feature_X = X.drop(columns=sensitive_cols, errors=\"ignore\")\n",
    "\n",
    "cat_cols = feature_X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "num_cols = feature_X.select_dtypes(exclude=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns ({len(cat_cols)}): {cat_cols}\")\n",
    "print(f\"Numeric columns ({len(num_cols)}): {num_cols}\")\n",
    "\n",
    "# =========================\n",
    "# 5) Pipelines (version-robust)\n",
    "# =========================\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "ohe_params = {}\n",
    "if \"sparse_output\" in inspect.signature(OneHotEncoder).parameters:\n",
    "    ohe_params[\"sparse_output\"] = False  # sklearn >= 1.2\n",
    "else:\n",
    "    ohe_params[\"sparse\"] = False         # sklearn < 1.2\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", **ohe_params)),\n",
    "])\n",
    "\n",
    "def make_preprocessor():\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipe, num_cols),\n",
    "            (\"cat\", categorical_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# 6) Split before preprocess; save 5 splits\n",
    "# =========================\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "seeds = [42, 202, 777, 1234, 9001]\n",
    "\n",
    "for i, seed in enumerate(seeds, start=1):\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "        feature_X, y_encoded, test_size=0.20, random_state=seed, stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    sens_train = X.loc[X_train_raw.index, sensitive_cols].copy()\n",
    "    sens_test  = X.loc[X_test_raw.index, sensitive_cols].copy()\n",
    "\n",
    "    preprocessor = make_preprocessor()\n",
    "    X_train_processed = preprocessor.fit_transform(X_train_raw)\n",
    "    X_test_processed  = preprocessor.transform(X_test_raw)\n",
    "\n",
    "    try:\n",
    "        processed_feature_names = preprocessor.get_feature_names_out()\n",
    "    except AttributeError:\n",
    "        ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        try:\n",
    "            ohe_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "        except AttributeError:\n",
    "            ohe_feature_names = ohe.get_feature_names(cat_cols)\n",
    "        processed_feature_names = np.array(list(num_cols) + list(ohe_feature_names))\n",
    "\n",
    "    df_train = pd.DataFrame(X_train_processed, columns=processed_feature_names, index=X_train_raw.index)\n",
    "    df_test  = pd.DataFrame(X_test_processed,  columns=processed_feature_names, index=X_test_raw.index)\n",
    "\n",
    "    df_train[\"target\"] = y_train\n",
    "    df_test[\"target\"] = y_test\n",
    "\n",
    "    for col in sensitive_cols:\n",
    "        df_train[col] = sens_train[col].values\n",
    "        df_test[col]  = sens_test[col].values\n",
    "\n",
    "    train_path = f\"data/diab_hosp_split{i}_train.csv\"\n",
    "    test_path  = f\"data/diab_hosp_split{i}_test.csv\"\n",
    "    df_train.to_csv(train_path, index=False)\n",
    "    df_test.to_csv(test_path, index=False)\n",
    "\n",
    "    print(f\"[Split {i}] seed={seed} saved:\")\n",
    "    print(f\"  {train_path} -> {df_train.shape}\")\n",
    "    print(f\"  {test_path}  -> {df_test.shape}\")\n",
    "\n",
    "print(\"\\nDone. True/False values for medicare/medicaid are preserved; 5 splits saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02219a-08ba-4c18-b896-d109f7f9ac12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
